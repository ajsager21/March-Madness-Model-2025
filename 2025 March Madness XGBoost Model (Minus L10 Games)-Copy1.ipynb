{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Add new game results\n",
    "#Step 2: Update all attributes including L10 games \n",
    "#Step 4: Hyperparameter tune this (below)\n",
    "#Step 5: Add hyperparameter tuning to other notebook\n",
    "#Step 7: Run the Bracket Code with the seedings put in to both cells\n",
    "#Step 8: Make a small sample game results bracket once done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter Tuning once we have finalized data:\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    " #Define the hyperparameter grid\n",
    "#param_grid = {\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'subsample': [0.6, 0.8, 1.0],\n",
    "#     'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "#xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Perform grid search\n",
    "#grid_search = GridSearchCV(\n",
    "#     estimator=xgb_model,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,  # 5-fold cross-validation\n",
    "#     verbose=2,\n",
    "#     n_jobs=-1\n",
    " #)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "#grid_search.fit(X, y)\n",
    "\n",
    "#Print the best parameters and score\n",
    "#print(\"Best Parameters:\", grid_search.best_params_)\n",
    "#print(\"Best Score:\", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6cdb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "# Load data\n",
    "game_results = pd.read_csv('/Users/a.j.sager/Desktop/March Madness Code/game_results_2025.csv')\n",
    "team_stats = pd.read_csv('/Users/a.j.sager/Desktop/March Madness Code/2024-2025 March Madness Data.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Merge datasets on team 1 and team 2\n",
    "merged = game_results.merge(\n",
    "    team_stats, left_on=\"team_1\", right_on=\"Team\", how=\"left\", suffixes=(\"\", \"_team1\")\n",
    ").merge(\n",
    "    team_stats, left_on=\"team_2\", right_on=\"Team\", how=\"left\", suffixes=(\"\", \"_team2\")\n",
    ")\n",
    "\n",
    "# Drop redundant 'Team' columns\n",
    "merged = merged.drop(columns=[\"Team\", \"Team_team2\"])\n",
    "\n",
    "# Calculate feature differences\n",
    "# Rest of Features are redacted\n",
    "stat_columns = [\n",
    "    \"PPG\", \"OPPG\", \"TO/Game\"\n",
    "]\n",
    "for col in stat_columns:\n",
    "    merged[f\"{col}_diff\"] = merged[f\"{col}\"] - merged[f\"{col}_team2\"]\n",
    "\n",
    "# Drop rows where 'outcome' column or other critical columns have NaN values\n",
    "merged.dropna(subset=['outcome'], inplace=True)\n",
    "\n",
    "merged['game_date'] = pd.to_datetime(merged['game'])\n",
    "\n",
    "# Compute time-based sample weights\n",
    "merged['days_since_start'] = (merged['game_date'] - merged['game_date'].min()).dt.days\n",
    "merged['game_weight'] = 1 + (merged['days_since_start'] / merged['days_since_start'].max())\n",
    "\n",
    "# Define features and target\n",
    "X = merged[[f\"{col}_diff\" for col in stat_columns]]\n",
    "y = merged[\"outcome\"]\n",
    "weights = merged[\"game_weight\"]  # Use these weights for training\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set the best hyperparameters obtained from grid search\n",
    "best_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 50,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 1.0\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier with the best parameters\n",
    "model = xgb.XGBClassifier(**best_params, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Perform 5-fold cross-validation and evaluate model\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.2f}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {cv_scores.std():.2f}\")\n",
    "\n",
    "# Feature importance plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "xgb.plot_importance(model, max_num_features=10, importance_type='gain', title='Feature Importance')\n",
    "plt.show()\n",
    "\n",
    "# SHAP Visualization (after fitting the model)\n",
    "# Initialize SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\")\n",
    "\n",
    "# Detailed force plot for the first prediction\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0], X.iloc[0])\n",
    "# Function to predict winner and assign spread\n",
    "def predict_winner_with_spread(team_1, team_2):\n",
    "    # Get stats for both teams\n",
    "    team_1_stats = team_stats[team_stats[\"Team\"] == team_1].iloc[0]\n",
    "    team_2_stats = team_stats[team_stats[\"Team\"] == team_2].iloc[0]\n",
    "\n",
    "    # Determine the correct order using NET Ranking or BPI\n",
    "    team_1_first = team_1_stats[\"NET Ranking\"] <= team_2_stats[\"NET Ranking\"]  # Lower ranking is better\n",
    "\n",
    "    if not team_1_first:\n",
    "        team_1_stats, team_2_stats = team_2_stats, team_1_stats  # Swap teams\n",
    "        swapped = True\n",
    "    else:\n",
    "        swapped = False\n",
    "\n",
    "    # Compute feature differences\n",
    "    features = [team_1_stats[col] - team_2_stats[col] for col in stat_columns]\n",
    "\n",
    "    # Predict probability\n",
    "    prob = model.predict_proba([features])[0][1]\n",
    "\n",
    "    # Ensure prob is within the expected range [0, 1]\n",
    "    prob = max(0, min(prob, 1))\n",
    "\n",
    "    # Adjust probability if order was swapped\n",
    "    if swapped:\n",
    "        prob = 1 - prob\n",
    "\n",
    "    # Calculate spread based on probability\n",
    "    if prob >= 0.95:\n",
    "        spread = \"-15.5\"\n",
    "    elif prob >= 0.92:\n",
    "        spread = \"-14.5\"\n",
    "    elif prob >= 0.90:\n",
    "        spread = \"-13.5\"\n",
    "    elif prob >= 0.875:\n",
    "        spread = \"-12.5\"\n",
    "    elif prob >= 0.825:\n",
    "        spread = \"-11.5\"\n",
    "    elif prob >= 0.80:\n",
    "        spread = \"-10.5\"\n",
    "    elif prob >= 0.75:\n",
    "        spread = \"-9.5\"\n",
    "    elif prob >= 0.725:\n",
    "        spread = \"-8.5\"\n",
    "    elif prob >= 0.70:\n",
    "        spread = \"-7.5\"\n",
    "    elif prob >= 0.675:\n",
    "        spread = \"-6.5\"\n",
    "    elif prob >= 0.65:\n",
    "        spread = \"-5.5\"\n",
    "    elif prob >= 0.625:\n",
    "        spread = \"-4.5\"\n",
    "    elif prob >= 0.60:\n",
    "        spread = \"-3.5\"\n",
    "    elif prob >= 0.575:\n",
    "        spread = \"-2.5\"\n",
    "    elif prob >= 0.55:\n",
    "        spread = \"-1.5\"\n",
    "    elif prob >= 0.525:\n",
    "        spread = \"-0.5\"\n",
    "    elif prob >= 0.50:\n",
    "        spread = \"Even\"\n",
    "    elif prob >= 0.475:\n",
    "        spread = \"+0.5\"\n",
    "    elif prob >= 0.45:\n",
    "        spread = \"+1.5\"\n",
    "    elif prob >= 0.425:\n",
    "        spread = \"+2.5\"\n",
    "    elif prob >= 0.40:\n",
    "        spread = \"+3.5\"\n",
    "    elif prob >= 0.375:\n",
    "        spread = \"+4.5\"\n",
    "    elif prob >= 0.35:\n",
    "        spread = \"+5.5\"\n",
    "    elif prob >= 0.30:\n",
    "        spread = \"+6.5\"\n",
    "    elif prob >= 0.25:\n",
    "        spread = \"+7.5\"\n",
    "    elif prob >= 0.20:\n",
    "        spread = \"+8.5\"\n",
    "    elif prob >= 0.15:\n",
    "        spread = \"+9.5\"\n",
    "    elif prob >= 0.10:\n",
    "        spread = \"+10.5\"\n",
    "    elif prob >= 0.05:\n",
    "        spread = \"+11.5\"\n",
    "    else:\n",
    "        spread = \"+12.5\"  # For probabilities closer to 0\n",
    "\n",
    "    # If Team 1 is less likely to win, adjust spread to reflect Team 2 as the favorite\n",
    "    if not swapped:\n",
    "        if prob < 0.50:\n",
    "            spread = f\"+{spread[1:]}\"  # Adjust for Team 2 as the favorite\n",
    "    else:\n",
    "        if prob >= 0.50:\n",
    "            spread = f\"-{spread[1:]}\"  # Adjust for Team 1 as the favorite\n",
    "\n",
    "    # Always print in the original input order\n",
    "    print(f\"The chance of {team_1} beating {team_2} is {prob:.2%}\")\n",
    "    print(f\"Spread: {team_1} {spread}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b5c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and call the function\n",
    "team_1 = input(\"Enter Team 1: \")\n",
    "team_2 = input(\"Enter Team 2: \")\n",
    "\n",
    "predict_winner_with_spread(team_1, team_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading/trailing whitespace and drop any rows with NaN values in the 'Team' column\n",
    "team_stats['Team'] = team_stats['Team'].str.strip()  # Strip extra spaces\n",
    "team_stats = team_stats.dropna(subset=['Team'])  # Drop rows with NaN values in the 'Team' column\n",
    "\n",
    "# Ensure no duplicates exist\n",
    "team_stats = team_stats.drop_duplicates(subset=['Team'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe4a5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an empty dictionary to store the wins for each team\n",
    "team_wins = {team: 0 for team in team_stats[\"Team\"]}\n",
    "\n",
    "# Iterate over all pairs of teams and calculate the win probability for team 1\n",
    "for team_1 in team_stats[\"Team\"]:\n",
    "    for team_2 in team_stats[\"Team\"]:\n",
    "        if team_1 != team_2:  # Skip comparisons of the same team\n",
    "            try:\n",
    "                # Get stats for the two teams\n",
    "                team_1_stats = team_stats[team_stats[\"Team\"] == team_1].iloc[0]\n",
    "                team_2_stats = team_stats[team_stats[\"Team\"] == team_2].iloc[0]\n",
    "                \n",
    "                # Compute feature differences\n",
    "                features = [\n",
    "                    team_1_stats[col] - team_2_stats[col] for col in stat_columns\n",
    "                ]\n",
    "                \n",
    "                # Predict the probability of team_1 winning\n",
    "                probability_team_1_wins = model.predict_proba([features])[0][1]\n",
    "                \n",
    "                # If team_1 wins, increment their win count\n",
    "                if probability_team_1_wins > 0.5:\n",
    "                    team_wins[team_1] += 1\n",
    "\n",
    "            except IndexError as e:\n",
    "                # Print a message if a team doesn't have stats in the dataset\n",
    "                print(f\"Error processing match between {team_1} and {team_2}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "win_counts = pd.DataFrame(list(team_wins.items()), columns=[\"Team\", \"Wins\"])\n",
    "win_counts = win_counts.sort_values(by=\"Wins\", ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f309553",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af39b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
